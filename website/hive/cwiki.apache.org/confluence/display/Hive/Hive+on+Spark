<!DOCTYPE html>
<html>
<head>
                    <title>Hive on Spark - Apache Hive - Apache Software Foundation</title>
    
        

                        
    
                        
    

                
    
    <meta http-equiv="X-UA-Compatible" content="IE=EDGE,chrome=IE7">
<meta charset="UTF-8">
<meta id="confluence-context-path" name="confluence-context-path" content="/confluence">
<meta id="confluence-base-url" name="confluence-base-url" content="https://cwiki.apache.org/confluence">

<meta id="atlassian-token" name="atlassian-token" content="735c8f668271f8e1dea73527ae5689ca93f07505">


<meta id="confluence-space-key" name="confluence-space-key" content="Hive">
<script type="text/javascript">
        var contextPath = '/confluence';
</script>

    

    <meta name="confluence-request-time" content="1451833703725">
        
    
        
            <meta name="ajs-is-space-admin" content=""> <meta name="ajs-has-space-config" content="">
            <style>.ia-fixed-sidebar, .ia-splitter-left {width: 285px;}.theme-default .ia-splitter #main {margin-left: 285px;}.ia-fixed-sidebar {visibility: hidden;}</style>
            <meta name="ajs-use-keyboard-shortcuts" content="true">
            <meta name="ajs-discovered-plugin-features" content="$discoveredList">
            <meta name="ajs-keyboardshortcut-hash" content="38450baaed51271899c8e867d2a48ca9">
            <meta name="ajs-is-confluence-admin" content="false">
            <meta name="ajs-connection-timeout" content="10000">
            <meta name="gliffy-license-type" content="LicenseType&lt;COMMUNITY&gt;">
<meta name="gliffy-license-quantity" content="${pluginLicenseManager.userCount}">

            <script type="text/x-template" title="gliffy-webpanel-footer">
        <div class="gliffy-webpanel-footer"><span>This Confluence installation runs a Free Gliffy License - Evaluate the <a href="http://www.gliffy.com/products/confluence-plugin/">Gliffy Confluence Plugin</a> for your Wiki!</span></div>
</script>


            
    
    
            <meta name="ajs-page-id" content="42567714">
            <meta name="ajs-latest-page-id" content="42567714">
            <meta name="ajs-content-type" content="page">
            <meta name="ajs-page-title" content="Hive on Spark">
            <meta name="ajs-parent-page-title" content="DesignDocs">
            <meta name="ajs-parent-page-id" content="27362075">
            <meta name="ajs-space-key" content="Hive">
            <meta name="ajs-space-name" content="Apache Hive">
            <meta name="ajs-jira-metadata-count" content="0">
            <meta name="ajs-from-page-title" content="">
            <meta name="ajs-can-remove-page" content="false">
            <meta name="ajs-browse-page-tree-mode" content="view">
            <meta name="ajs-shared-drafts" content="false">
            <meta name="ajs-context-path" content="/confluence">
            <meta name="ajs-base-url" content="https://cwiki.apache.org/confluence">
            <meta name="ajs-version-number" content="5.8.4">
            <meta name="ajs-build-number" content="5982">
            <meta name="ajs-remote-user" content="">
            <meta name="ajs-remote-user-key" content="">
            <meta name="ajs-current-user-fullname" content="">
            <meta name="ajs-current-user-avatar-url" content="">
            <meta name="ajs-static-resource-url-prefix" content="/confluence/s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_">
            <meta name="ajs-global-settings-attachment-max-size" content="20971520">
            <meta name="ajs-user-locale" content="en_GB">
            <meta name="ajs-enabled-dark-features" content="confluence-inline-comments-resolved,notification.plugin.api.enabled.com.atlassian.confluence.plugins.sharepage.api.ShareContentEvent,notification.plugin.api.enabled.com.atlassian.confluence.plugins.mentions.api.ConfluenceMentionEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.security.ForgotPasswordEvent,pdf-preview,notification.plugin.api.enabled.com.atlassian.confluence.plugins.tasklist.event.SendTaskEmailEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.page.async.PageMovedEvent,previews.sharing,previews.versions,notification.plugin.api.enabled.com.atlassian.confluence.plugins.files.notifications.event.FileContentUpdateEvent,file-annotations,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.attachment.AttachmentBatchUploadCompletedEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.comment.CommentCreateEvent,notification.plugin.api.enabled.com.atlassian.confluence.efi.emails.events.OnboardingLessUsersEvent,notification.plugin.api.enabled.com.atlassian.confluence.plugins.files.notifications.event.FileContentRemoveEvent,atlassian.aui.raphael.disabled,previews.conversion-service,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.comment.CommentUpdateEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.follow.FollowEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.page.async.PageEditedEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.blogpost.BlogPostCreateEvent,previews.trigger-all-file-types,notification.plugin.api.enabled.com.atlassian.confluence.plugins.inlinecomments.events.InlineCommentResolveEvent,notification.plugin.api.enabled.com.atlassian.confluence.event.events.like.LikeCreatedEvent,notification.plugin.api.enabled.com.atlassian.confluence.plugins.inlinecomments.events.InlineCommentCreateEvent,previews.sharing.pushstate,confluence-inline-comments-rich-editor,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.blogpost.BlogPostUpdateEvent,file-annotations.likes,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.page.async.PageCreatedEvent,notification.plugin.api.enabled.com.atlassian.confluence.plugins.files.notifications.event.FileContentMentionUpdateEvent,notification.plugin.api.enabled.com.atlassian.confluence.efi.emails.events.OnboardingNoSpaceCreatedEvent,notification.plugin.api.enabled.com.atlassian.confluence.plugins.hipchat.api.events.HipChatUserMapped,notification.plugin.api.enabled.com.atlassian.confluence.plugins.sharepage.api.ShareAttachmentEvent,confluence-inline-comments,confluence-inline-comments-dangling-comment,notification.plugin.api.enabled.com.atlassian.confluence.event.events.content.blogpost.BlogPostMovedEvent">
            <meta name="ajs-atl-token" content="735c8f668271f8e1dea73527ae5689ca93f07505">
            <meta name="ajs-confluence-flavour" content="VANILLA">
            <meta name="ajs-user-date-pattern" content="dd MMM yyyy">
            <meta name="ajs-date.format" content="MMM dd, yyyy">
    
    <link rel="shortcut icon" href="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_/favicon.ico">
    <link rel="icon" type="image/x-icon" href="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_/favicon.ico">

<link rel="search" type="application/opensearchdescription+xml" href="https://cwiki.apache.org/confluence/opensearch/osd.action" title="Apache Software Foundation"/>
    
                    
            <meta name="ajs-create-issue-metadata-show-discovery" content="false">
            

<script>
window.WRM=window.WRM||{};window.WRM._unparsedData=window.WRM._unparsedData||{};
WRM._unparsedData["com.atlassian.plugins.atlassian-plugins-webresource-plugin:context-path.context-path"]="\"/confluence\"";
WRM._unparsedData["com.atlassian.plugins.atlassian-nps-plugin:atlassian-nps-plugin-resources.is-server-instance-data-provider"]="true";
WRM._unparsedData["com.atlassian.plugins.browser.metrics.browser-metrics-plugin:browser-metrics.feature-data-provider-legacy"]="true";
WRM._unparsedData["com.atlassian.plugins.atlassian-plugins-webresource-rest:web-resource-manager.resource-base-url-pattern"]="\"(?:/confluence(?:/s/.*?/_)?/download)\"";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-license-banner:confluence-license-banner-resources.license-details"]="{\"daysBeforeLicenseExpiry\":0,\"daysBeforeMaintenanceExpiry\":0,\"showLicenseExpiryBanner\":false,\"showMaintenanceExpiryBanner\":false,\"renewUrl\":null,\"salesEmail\":null}";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-hipchat-integration-plugin:discovery-javascript-data.link-active"]="{\"linkActive\":true,\"conditionsMet\":true,\"admin\":false}";
WRM._unparsedData["com.atlassian.plugins.atlassian-nps-plugin:nps-acknowledgement-resources.analytics-enabled-data-provider"]="\"true\"";
WRM._unparsedData["com.atlassian.plugins.atlassian-nps-plugin:nps-acknowledgement-resources.sen-data-provider"]="\"SEN-2015076\"";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-feature-discovery-plugin:confluence-feature-discovery-plugin-resources.test-mode"]="false";
WRM._unparsedData["com.atlassian.plugins.browser.metrics.browser-metrics-plugin:api.feature-data-provider"]="true";
</script>
<link type="text/css" rel="stylesheet" href="../../s/2e51e60e83eadbb79c5004bd9c4ac765-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/68/_/download/superbatch/css/batch.css@build-number=5982" media="all">
<!--[if lt IE 9]>
<link type="text/css" rel="stylesheet" href="/confluence/s/d41d8cd98f00b204e9800998ecf8427e-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/68/_/download/superbatch/css/batch.css?conditionalComment=lt+IE+9" media="all">
<![endif]-->
<!--[if lte IE 9]>
<link type="text/css" rel="stylesheet" href="/confluence/s/d41d8cd98f00b204e9800998ecf8427e-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/68/_/download/superbatch/css/batch.css?conditionalComment=lte+IE+9" media="all">
<![endif]-->
<link type="text/css" rel="stylesheet" href="../../s/9b6bdeb7fddc0a2f5337e313f4e85615-T/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/ec13b76cd8d002fa2cf4ca229002aee7/_/download/contextbatch/css/page,viewcontent,atl.general,main,pagebanner,atl.comments/batch.css@highlightactions=true&amp;locale=en-GB&amp;flavour=VANILLA" media="all">
<!--[if lt IE 9]>
<link type="text/css" rel="stylesheet" href="/confluence/s/6c0981174e94142364564819dc0d1413-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/ec13b76cd8d002fa2cf4ca229002aee7/_/download/contextbatch/css/page,viewcontent,atl.general,main,pagebanner,atl.comments/batch.css?conditionalComment=lt+IE+9&amp;locale=en-GB" media="all">
<![endif]-->
<link type="text/css" rel="stylesheet" href="../../s/d41d8cd98f00b204e9800998ecf8427e-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/2.8.6/_/download/batch/org.randombits.confluence.toc%253Atoc-plugin-styles/org.randombits.confluence.toc%253Atoc-plugin-styles.css" media="all">
<link type="text/css" rel="stylesheet" href="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/13/_/styles/colors.css@spaceKey=Hive" media="all">
<link type="text/css" rel="stylesheet" href="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/1.0/_/download/resources/com.atlassian.confluence.themes.default%253Astyles/default-theme.css" media="all">
<script type="text/javascript" src="../../s/b5b7f3c4a47ebde54b884c3070e3bb8c-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/68/_/download/superbatch/js/batch.js@atlassian.aui.raphael.disabled=true&amp;locale=en-GB&amp;build-number=5982" ></script>
<script type="text/javascript" src="../../s/47fb273cd38c3662368839aefb134f70-T/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/ec13b76cd8d002fa2cf4ca229002aee7/_/download/contextbatch/js/page,viewcontent,atl.general,main,pagebanner,atl.comments/batch.js@highlightactions=true&amp;analytics-uploadable=true&amp;flavour=VANILLA&amp;nps-acknowledged=true&amp;analytics-enabled=true&amp;locale=en-GB&amp;anonymous-access-enabled=true&amp;is-server-instance=true&amp;hostenabled=true" ></script>
<script type="text/javascript" src="../../s/d41d8cd98f00b204e9800998ecf8427e-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/2.8.6/_/download/batch/org.randombits.confluence.toc%253Aclient-side-toc-resources/org.randombits.confluence.toc%253Aclient-side-toc-resources.js" ></script>
<script type="text/javascript" src="../../s/d41d8cd98f00b204e9800998ecf8427e-CDN/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/2.8.6/_/download/batch/org.randombits.confluence.toc%253Atoc-plugin-analytics/org.randombits.confluence.toc%253Atoc-plugin-analytics.js" ></script>


        
    

        
        <meta name="ajs-site-title" content="Apache Software Foundation" />

    
    

    
                <link rel="canonical" href="Hive+on+Spark">
        <link rel="shortlink" href="https://cwiki.apache.org/confluence/x/IoiJAg">
    <meta name="wikilink" content="[Hive:Hive on Spark]">
    <meta name="page-version" content="9">

</head>

<body             onload="placeFocus()"
     id="com-atlassian-confluence" class="theme-default  aui-layout aui-theme-default">

        
            <div id='stp-licenseStatus-banner'></div>
    <ul id="assistive-skip-links" class="assistive">
    <li><a href="Hive+on+Spark#title-heading">Skip to content</a></li>
    <li><a href="Hive+on+Spark#breadcrumbs">Skip to breadcrumbs</a></li>
    <li><a href="Hive+on+Spark#header-menu-bar">Skip to header menu</a></li>
    <li><a href="Hive+on+Spark#navigation">Skip to action menu</a></li>
    <li><a href="Hive+on+Spark#quick-search-query">Skip to quick search</a></li>
</ul>
<div id="page">
<div id="full-height-container">
    <div id="header-precursor">
        <div class="cell">
            <style type="text/css">
#preview #previewArea iframe {

   overflow: visible;
}
</style>

                            </div>
    </div>
    



<header id="header" role="banner">
    <nav class="aui-header aui-dropdown2-trigger-group" role="navigation"><div class="aui-header-inner"><div class="aui-header-before"><a class=" aui-dropdown2-trigger app-switcher-trigger" aria-owns="app-switcher" aria-controls="app-switcher" aria-haspopup="true" data-aui-trigger href="Hive+on+Spark#app-switcher"><span class="aui-icon aui-icon-small aui-iconfont-appswitcher">Linked Applications</span></a><div id="app-switcher" class="aui-dropdown2 aui-style-default"><div class="app-switcher-loading">Loading&hellip;</div></div><script>
            (function (NL) {
                var initialise = function () {
                    // For some milestones of AUI, the atlassian soy namespace was renamed to aui. Handle that here by ensuring that window.atlassian is defined.
                    window.atlassian = window.atlassian || window.aui;
                    new NL.AppSwitcher({
                        dropdownContents: '#app-switcher'
                    });
                };
                if (NL.AppSwitcher) {
                    initialise();
                } else {
                    NL.onInit = initialise;
                }
            }(window.NL = (window.NL || {})));
            window.NL.isUserAdmin = false</script></div><div class="aui-header-primary"><h1 id="logo" class="aui-header-logo aui-header-logo-custom"><a href="https://cwiki.apache.org/confluence/"><img src="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_/images/logo/confluence-logo.png" alt="Apache Software Foundation" /></a></h1><ul class="aui-nav">
                            <li>
            
        
        
<a  id="space-directory-link" href="https://cwiki.apache.org/confluence/spacedirectory/view.action"  class=" aui-nav-imagelink"   title="Spaces">
            <span>Spaces</span>
    </a>
        </li>
                        </ul>
</div><div class="aui-header-secondary"><ul class="aui-nav">
                        <li>
        <form id="quick-search" class="aui-quicksearch dont-default-focus header-quicksearch" action="https://cwiki.apache.org/confluence/dosearchsite.action" method="get"><fieldset><label for="quick-search-query" class="assistive">Quick Search</label><input id="quick-search-query" class="text app-search search quick-search-query" type="text" accessKey="q" autocomplete="off" name="queryString" title="Quick Search" placeholder="Search" /><input id="quick-search-submit" class="quick-search-submit" type="submit" value="Search"/><div class="aui-dd-parent quick-nav-drop-down"></div></fieldset></form>
    </li>
        <li>
            
        <a id="help-menu-link" class="aui-nav-link aui-dropdown2-trigger" href="Hive+on+Spark#" aria-haspopup="true" aria-owns="help-menu-link-content" title="Help">
        <span class="aui-icon aui-icon-small aui-iconfont-help">Help</span>
    </a>
    <nav id="help-menu-link-content" class="aui-dropdown2 aui-style-default" aria-hidden="true">
                    <div class="aui-dropdown2-section">
                                <ul  id="help-menu-link-leading" class="aui-list-truncate section-leading first">
                                            <li>
        
            
<a  id="confluence-help-link" href="https://docs.atlassian.com/confluence/docs-58/Getting+Help+And+Support" class="    "      title="Visit the Confluence documentation home"  target="_blank"
>
        Online Help
</a>
</li>
                                            <li>
    
            
<a  id="keyboard-shortcuts-link" href="https://cwiki.apache.org/confluence" class="    "      title="View available keyboard shortcuts" >
        Keyboard Shortcuts
</a>
</li>
                                            <li>
    
            
<a  id="feed-builder-link" href="https://cwiki.apache.org/confluence/dashboard/configurerssfeed.action" class="    "      title="Create your custom RSS feed." >
        Feed Builder
</a>
</li>
                                            <li>
    
            
<a  id="whats-new-menu-link" href="https://docs.atlassian.com/confluence/docs-58/whatsnew/iframe" class="    "      title="" >
        What’s new
</a>
</li>
                                            <li>
    
            
<a  id="whats-new-menu-link" href="https://docs.atlassian.com/confluence/docs-58/whatsnew/iframe" class="    "      title="" >
        What’s new
</a>
</li>
                                            <li>
    
            
<a  id="gadget-directory-link" href="https://cwiki.apache.org/confluence" class="   user-item administration-link "      title="Browse gadgets provided by Confluence" >
        Available Gadgets
</a>
</li>
                                            <li>
    
            
<a  id="confluence-about-link" href="https://cwiki.apache.org/confluence/aboutconfluencepage.action" class="    "      title="Get more information about Confluence" >
        About Confluence
</a>
</li>
                                    </ul>
            </div>
            </nav>
    
    </li>
        <li>
                
    
    </li>
        <li>
            
    </li>
        <li>
                                            <li>
        
            
<a  id="login-link" href="https://cwiki.apache.org/confluence/login.action?os_destination=%2Fdisplay%2FHive%2FHive%2Bon%2BSpark" class="   user-item login-link "      title="" >
        Log in
</a>
</li>
                        <li>
    
            
<a  id="signup-link" href="https://cwiki.apache.org/confluence/signup.action" class="   user-item signup-link "      title="" >
        Sign up
</a>
</li>
                        
    </li>
    </ul>
</div></div><!-- .aui-header-inner--></nav><!-- .aui-header -->
    <br class="clear">
</header>

    
    	<div class="ia-splitter">
    		<div class="ia-splitter-left">
    			<div class="ia-fixed-sidebar">
    				
	    	<div class="acs-side-bar ia-scrollable-section"><div class="acs-side-bar-space-info tipsy-enabled" data-configure-tooltip="Edit space details"><div class="avatar"><div class="space-logo " data-key="Hive" data-name="Apache Hive" data-entity-type="confluence.space"><div class="avatar-img-container"><div class="avatar-img-wrapper"><a href="https://cwiki.apache.org/confluence/display/Hive" title="Apache Hive"><img class="avatar-img" src="../../download/attachments/27362113/Hive@version=2&amp;modificationDate=1317659390000&amp;api=v2" alt="Apache Hive"></a></div></div></div></div><div class="name"><a href="https://cwiki.apache.org/confluence/display/Hive" title="Apache Hive">Apache Hive</a></div><div class="flyout-handle icon"></div></div><div class="acs-side-bar-content"><div class="acs-nav-wrapper"><div class="acs-nav" data-has-create-permission="false" data-quick-links-state="null" data-nav-type="pages"><div class="acs-nav-sections"><div class="main-links-section "><ul class="acs-nav-list"><li class="acs-nav-item wiki current-item"data-collector-key="spacebar-pages"><a class="acs-nav-item-link tipsy-enabled" href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive" data-collapsed-tooltip="Pages"><span class="icon"></span><span class="acs-nav-item-label">Pages</span></a></li><li class="acs-nav-item blog"data-collector-key="spacebar-blogs"><a class="acs-nav-item-link tipsy-enabled" href="https://cwiki.apache.org/confluence/pages/viewrecentblogposts.action?key=Hive" data-collapsed-tooltip="Blog"><span class="icon"></span><span class="acs-nav-item-label">Blog</span></a></li></ul></div><div class="quick-links-wrapper"></div></div></div></div><div class="ia-secondary-container tipsy-enabled" data-tree-type="pages"><div class="ia-secondary-header"><h5 class="ia-secondary-header-title pages"><span class="label">Child pages</span></h5></div><div class="ia-secondary-parent-content"><ul class="parent ia-secondary-header-title wiki"><li class="parent-item"><a class="parent-item-link" href="DesignDocs" title="DesignDocs"><span class="icon"></span><span class="label">DesignDocs</span></a></li></ul></div><div class="ia-secondary-current-content"><ul class="ia-secondary-currentPage-title wiki current-item"><li><span class="icon"></span><span class="label">Hive on Spark</span></li></ul></div><div class="ia-secondary-content"><div class="contextual-nav-child-pages"></div></div></div></div><div class="hidden"><a href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive" id="space-pages-link"></a><script type="text/x-template" title="logo-config-content"><h2>Space Details</h2><div class="personal-space-logo-hint">Your profile picture is used as the logo for your personal space. <a href="https://cwiki.apache.org/confluence/users/profile/editmyprofilepicture.action" target="_blank">Change your profile picture</a>.</div></script></div></div><div class="space-tools-section"><div id="space-tools-menu-additional-items" class="hidden"><div data-label="Browse pages" data-class="" data-href="/confluence/pages/reorderpages.action?key=Hive">Browse pages</div></div><div id="space-tools-dd-dummy"></div><a id="space-tools-menu-trigger" class="aui-button aui-button-subtle aui-dropdown2-trigger tipsy-enabled" aria-owns="space-tools-dd-dummy"><span class="aui-icon aui-icon-small aui-iconfont-configure">Configure</span><span class="label">Space tools</span></a><a class="expand-collapse-trigger"></a></div>
    
    			</div>
    		</div>
        <!-- \#header -->

        
        <div id="main" class=" aui-page-panel">
                <div id="main-header">
            
    <div id="navigation" class="content-navigation view">
                    <ul class="ajs-menu-bar">
                                                        
                    
        <li class="normal ajs-menu-item">
        <a id="action-menu-link" class="action aui-dropdown2-trigger-arrowless aui-button aui-button-subtle ajs-menu-title aui-dropdown2-trigger" href="Hive+on+Spark#" aria-haspopup="true" aria-owns="action-menu" data-container="#navigation">
            <span>
                                    <span class="aui-icon aui-icon-small aui-iconfont-more"></span>
                                
            </span>
        </a>         <div id="action-menu" class="aui-dropdown2 aui-style-default">
                            <ul  id="action-menu-primary"                     class="section-primary first aui-dropdown2-section">
                                            <li>

    
        
                                            
    
    
    <a  id="view-attachments-link" href="https://cwiki.apache.org/confluence/pages/viewpageattachments.action?pageId=42567714" rel="nofollow" class="action-view-attachments"  accessKey="t"  title="View Attachments">
                <span>
                        A<u>t</u>tachments (0)
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="action-view-history-link" href="https://cwiki.apache.org/confluence/pages/viewpreviousversions.action?pageId=42567714" rel="nofollow" class="action-view-history"   title="">
                <span>
                        Page History
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="action-page-permissions-link" href="https://cwiki.apache.org/confluence/pages/viewinfo.action?pageId=42567714" rel="nofollow" class="action-page-permissions"   title="Edit restrictions">
                <span>
                        Restrictions
        </span>    </a>
</li>
                                </ul>
                            <ul  id="action-menu-secondary"                     class="section-secondary aui-dropdown2-section">
                                            <li>

    
        
                                            
    
    
    <a  id="view-page-info-link" href="https://cwiki.apache.org/confluence/pages/viewinfo.action?pageId=42567714" rel="nofollow" class="action-view-info"   title="">
                <span>
                        Page Information
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="view-resolved-comments" href="https://cwiki.apache.org/confluence" rel="nofollow" class=""   title="">
                <span>
                        Resolved comments
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="link-to-page-link" href="https://cwiki.apache.org/confluence/pages/viewinfo.action?pageId=42567714" rel="nofollow" class=""   title="Link to this Page">
                <span>
                        Link to this Page…
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="view-in-hierarchy-link" href="https://cwiki.apache.org/confluence/pages/reorderpages.action?key=Hive&amp;openId=42567714#selectedPageInHierarchy" rel="nofollow" class=""   title="">
                <span>
                        View in Hierarchy
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="action-view-source-link" href="https://cwiki.apache.org/confluence/plugins/viewsource/viewpagesrc.action?pageId=42567714" rel="nofollow" class="action-view-source popup-link"   title="">
                <span>
                        View Source
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="delete-all-comments-link-link" href="https://cwiki.apache.org/confluence/plugins/aptis/deleteAllComments/ask-user.action?pageId=42567714" rel="nofollow" class=""   title="">
                <span>
                        Delete comments
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="action-export-pdf-link" href="https://cwiki.apache.org/confluence/spaces/flyingpdf/pdfpageexport.action?pageId=42567714" rel="nofollow" class=""   title="">
                <span>
                        Export to PDF
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="com-k15t-confluence-scroll-epub-launcher" href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=42567714" rel="nofollow" class=""   title="">
                <span>
                        Export to EPUB
        </span>    </a>
</li>
                                        <li>

    
        
                                            
    
    
    <a  id="action-export-word-link" href="https://cwiki.apache.org/confluence/exportword?pageId=42567714" rel="nofollow" class="action-export-word"   title="">
                <span>
                        Export to Word
        </span>    </a>
</li>
                                </ul>
                            <ul  id="action-menu-modify"                     class="section-modify aui-dropdown2-section">
                                            <li>

    
        
                                            
    
    
    <a  id="treecopy-action" href="https://cwiki.apache.org/confluence/plugins/treecopy/setnames.action?pageId=42567714" rel="nofollow" class=""   title="">
                <span>
                        Copy Page Tree
        </span>    </a>
</li>
                                </ul>
                    </div>
    </li>
            </ul>
    </div>

            
            <div id="title-heading" class="pagetitle with-breadcrumbs">
                
                                    <div id="breadcrumb-section">
                        
    
    
    <ol id="breadcrumbs">
                                        
                        
        <li class="first" >
                        
                            <span class=""><a href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive">Pages</a></span>
                                                                    
                        
        <li>
                        
                            <span class=""><a href="DesignDocs">DesignDocs</a></span>
                                                    </ol>


                    </div>
                
                
        <a href="Hive+on+Spark#page-banner-end" class="assistive">Skip to end of banner</a>
<div id="page-banner-start" class="assistive"></div>

                    
            <div id="page-metadata-banner"><ul class="banner"><li id="system-content-items" class="noprint"><a href="Hive+on+Spark" title="Restrictions apply" id="content-metadata-page-restrictions" class="hidden"><img class="page-banner-item-icon" src="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_/download/resources/com.atlassian.confluence.plugins.confluence-page-banner%253Apage-banner-resources/images/red_padlock.png" style="height: 16px; width: 16px;"/></a></li><li class="page-metadata-item noprint has-button"  id="content-metadata-jira-wrapper"><a href="Hive+on+Spark" title="" id="content-metadata-jira" class="aui-button aui-button-subtle content-metadata-jira tipsy-disabled hidden"><img class="page-banner-item-icon" src="../../s/en_GB/5982/f2b47fb3d636c8bc9fd0b11c0ec6d0ae18646be7.1/_/download/resources/com.atlassian.confluence.plugins.confluence-jira-metadata%253Aconfluence-jira-metadata-resources/img/icon-jira-link.png" style="height: 16px; width: 16px;"/><span>JIRA links</span></a></li></ul></div>
            

<a href="Hive+on+Spark#page-banner-start" class="assistive">Go to start of banner</a>
<div id="page-banner-end" class="assistive"></div>
    

                <h1 id="title-text" class="with-breadcrumbs">
                                                <a href="Hive+on+Spark">Hive on Spark</a>
                                    </h1>
            </div>
        </div><!-- \#main-header -->
        
        

        <div id="sidebar-container">
                                                </div><!-- \#sidebar-container -->

        
    

        




        

    
    
        
    
    
                    
    

                        
    
    

    




<div id="content" class="page view">
    


<div id="action-messages">
                        </div>



        <script type="text/x-template" title="searchResultsGrid">
    <table class="aui">
        <thead>
            <tr class="header">
                <th class="search-result-title">Page Title</th>
                <th class="search-result-space">Space</th>
                <th class="search-result-date">Updated</th>
            </tr>
        </thead>
    </table>
</script>
<script type="text/x-template" title="searchResultsGridCount">
    <p class="search-result-count">{0}</p>
</script>
<script type="text/x-template" title="searchResultsGridRow">
    <tr class="search-result">
        <td class="search-result-title"><a href="https://cwiki.apache.org/confluence/display/Hive/{1}" class="content-type-{2}"><span>{0}</span></a></td>
        <td class="search-result-space"><a class="space" href="https://cwiki.apache.org/confluence/display/{4}/" title="{3}">{3}</a></td>
        <td class="search-result-date"><span class="date" title="{6}">{5}</span></td>
    </tr>
</script>
        
    
            

        
                            
    

                    

        
        <a href="Hive+on+Spark#page-metadata-end" class="assistive">Skip to end of metadata</a>
<div id="page-metadata-start" class="assistive"></div>

    <div class="page-metadata">
        <ul>
            <li class="page-metadata-modification-info">
                
        
    
        
    
        
        
            Created by <span class='author'>     <a href="https://cwiki.apache.org/confluence/display/~xuefu"
                       class="url fn"
                            >Xuefu Zhang</a></span>, last modified by <span class='editor'>     <a href="https://cwiki.apache.org/confluence/display/~szehon"
                       class="url fn"
                            >Szehon Ho</a></span> on <a class='last-modified' title='Jan 12, 2015 23:22' href='https://cwiki.apache.org/confluence/pages/diffpagesbyversion.action?pageId=42567714&amp;selectedPageVersions=8&amp;selectedPageVersions=9'>Jan 12, 2015</a>
                </li>
        </ul>
    </div>


<a href="Hive+on+Spark#page-metadata-start" class="assistive">Go to start of metadata</a>
<div id="page-metadata-end" class="assistive"></div>

        
                                            
        <div id="main-content" class="wiki-content">
                           
        <p><div class="toc-macro client-side-toc-macro " data-headerelements="H1,H2,H3,H4,H5,H6,H7"></div></p><h1 id="HiveonSpark-1.Introduction"><span style="color: rgb(0,0,0);text-decoration: none;">1. Introduction</span></h1><p><span style="color: rgb(0,0,10);text-decoration: none;">We propose modifying Hive to add Spark as a third execution backend(<a href="https://issues.apache.org/jira/browse/HIVE-7292" class="external-link" rel="nofollow">HIVE-7292</a>), parallel to MapReduce and Tez.</span></p><p><span style="color: rgb(0,0,10);text-decoration: none;">Spark i</span><span style="color: rgb(0,0,0);text-decoration: none;">s an open-source data analytics cluster computing framework that’s built outside of Hadoop's two-stage MapReduce paradigm but on top of HDFS. Spark’s primary abstraction is a distributed collection of items called a Resilient Distributed Dataset (RDD). RDDs can be created from Hadoop </span><span style="color: rgb(0,0,0);text-decoration: none;">InputFormat</span><span style="color: rgb(0,0,0);text-decoration: none;">s (such as HDFS files) or by transforming other RDDs. By being applied by a series of transformations such as </span><span style="color: rgb(0,0,0);text-decoration: none;">groupBy</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">filter</span><span style="color: rgb(0,0,0);text-decoration: none;">, or actions such as </span><span style="color: rgb(0,0,0);text-decoration: none;">count</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">save</span><span style="color: rgb(0,0,0);text-decoration: none;"> that are provided by Spark, RDDs can be processed and analyzed to fulfill what MapReduce jobs can do without having intermediate stages.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">SQL queries can be easily translated into Spark transformation and actions, as demonstrated in Shark and Spark SQL. In fact, many primitive transformations and actions are SQL-oriented such as </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">count</span><span style="color: rgb(0,0,0);text-decoration: none;">.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">More information about Spark can be found here:</span></p><ul><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Apache Spark page: </span><a href="http://spark.apache.org/" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(17,85,204);text-decoration: underline;">http://spark.apache.org/</span></a></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Apache Spark blogpost: </span><a href="http://blog.cloudera.com/blog/2013/11/putting-spark-to-use-fast-in-memory-computing-for-your-big-data-applications/" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(17,85,204);text-decoration: underline;">http://blog.cloudera.com/blog/2013/11/putting-spark-to-use-fast-in-memory-computing-for-your-big-data-applications/</span></a></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Apache Spark JavaDoc:  </span><a href="http://spark.apache.org/docs/1.0.0/api/java/index.html" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(17,85,204);text-decoration: underline;">http://spark.apache.org/docs/1.0.0/api/java/index.html</span></a></p></li></ul><h2 id="HiveonSpark-1.1Motivation"><span style="color: rgb(0,0,0);text-decoration: none;">1.1 Motivation</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">Here are the main motivations for enabling Hive to run on Spark:</span></p><ol><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark user benefits: This feature is very valuable to users who are already using Spark for other data processing and machine learning needs. Standardizing on one execution backend is convenient for operational management, and makes it easier to develop expertise to debug issues and make enhancements.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Greater Hive adoption: Following the previous point, this brings Hive into the Spark user base as a SQL on Hadoop option, further increasing Hive’s adoption.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Performance: Hive queries, especially those involving multiple reducer stages, will run faster, thus improving user experience as Tez does.</span></p></li></ol><p><span style="color: rgb(0,0,0);text-decoration: none;">It is not a goal for the Spark execution backend to replace Tez or MapReduce. It is healthy for the Hive project for multiple backends to coexist. Users have a choice whether to use Tez, Spark or MapReduce. Each has different strengths depending on the use case. And the success of Hive does not completely depend on the success of either Tez or Spark.</span></p><h2 id="HiveonSpark-1.2DesignPrinciple"><span style="color: rgb(0,0,0);text-decoration: none;">1.2 Design Principle</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">The main design principle is to have no or limited impact on Hive’s existing code path and thus no functional or performance impact. That is, users choosing to run Hive on either MapReduce or Tez will have existing functionality and code paths as they do today. In addition, plugging in Spark at the execution layer keeps code sharing at maximum and contains the maintenance cost, so Hive community does not need to make specialized investments for Spark.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Meanwhile, users opting for Spark as the execution engine will automatically have all the rich functional features that Hive provides. Future features (such as new data types, UDFs, logical optimization, etc) added to Hive should be automatically available to those users without any customization work to be done done in Hive’s Spark execution engine.</span></p><h2 id="HiveonSpark-1.3ComparisonwithSharkandSparkSQL"><span style="color: rgb(0,0,0);text-decoration: none;">1.3 Comparison with Shark and Spark SQL</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">There are two related projects in the Spark ecosystem that provide Hive QL support on Spark: Shark and Spark SQL.</span></p><ul><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">The Shark project translates query plans generated by Hive into its own representation and executes them over Spark. </span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark SQL is a feature in Spark. It uses Hive’s parser as the frontend to provide Hive QL support. Spark application developers can easily express their data processing logic in SQL, as well as the other Spark operators, in their code. Spark SQL supports a different use case than Hive.</span></p></li></ul><p><span style="color: rgb(0,0,0);text-decoration: none;">Compared with Shark and Spark SQL, our approach by design supports all existing Hive features, including Hive QL (and any future extension), and Hive’s integration with authorization, monitoring, auditing, and other operational tools.</span></p><h2 id="HiveonSpark-1.4OtherConsiderations"><span style="color: rgb(0,0,0);text-decoration: none;">1.4 Other Considerations</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">We know that a new execution backend is a major undertaking. It inevitably adds complexity and maintenance cost, even though the design avoids touching the existing code paths. And Hive will now have unit tests running against MapReduce, Tez, and Spark. We think that the benefit outweighs the cost. From an infrastructure point of view, we can get sponsorship for more hardware to do continuous integration. </span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Lastly, Hive on Tez has laid some important groundwork that will be very helpful to support a new execution engine such as Spark. This project here will certainly benefit from that. On the other hand, Spark is a framework that’s very different from either MapReduce or Tez. Thus, it’s very likely to find gaps and hiccups during the integration. It’s expected that Hive community will work closely with Spark community to ensure the success of the integration.</span></p><h1 id="HiveonSpark-2.High-LevelFunctionality"><span style="color: rgb(0,0,0);text-decoration: none;">2. High-Level Functionality</span></h1><h2 id="HiveonSpark-2.1ANewExecutionEngine"><span style="color: rgb(0,0,0);text-decoration: none;">2.1 A New Execution Engine</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">We will introduce a new execution, Spark, in addition to existing MapReduce and Tez. To use Spark as an execution engine in Hive, set the following:</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">set hive.execution.engine=spark;</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">The default value for this configuration is still “</span><span style="color: rgb(0,0,0);text-decoration: none;">mr</span><span style="color: rgb(0,0,0);text-decoration: none;">”. Hive continues to work on MapReduce and Tez as is on clusters that don't have spark.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">The new execution engine should support all Hive queries without requiring any modification of the queries. Query result should be functionally equivalent to that from either MapReduce or Tez.</span></p><h2 id="HiveonSpark-2.2SparkConfiguration"><span style="color: rgb(0,0,0);text-decoration: none;">2.2 Spark Configuration</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">When Spark is configured as Hive's execution, a few configuration variables will be introduced such as the master URL of the Spark cluster. However, they can be completely ignored if Spark isn’t configured as the execution engine.</span></p><h2 id="HiveonSpark-2.3MiscellaneousFunctionality"><span style="color: rgb(0,0,0);text-decoration: none;">2.3 Miscellaneous Functionality</span></h2><ol><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Hive will display a task execution plan that’s similar to that being displayed in “</span><span style="color: rgb(0,0,0);text-decoration: none;">explain</span><span style="color: rgb(0,0,0);text-decoration: none;">” </span><span style="color: rgb(0,0,0);text-decoration: none;">    </span><span style="color: rgb(0,0,0);text-decoration: none;">command for MapReduce and Tez. </span><span style="color: rgb(0,0,0);text-decoration: none;">    </span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Hive will give appropriate feedback to the user about progress and completion status of the query when running queries on Spark.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">The user will be able to get statistics and diagnostic information as before (counters, logs, and debug info on the console).</span></p></li></ol><h1 id="HiveonSpark-3.Hive-LevelDesign"><span style="color: rgb(0,0,0);text-decoration: none;">3. Hive-Level Design</span></h1><p><span style="color: rgb(0,0,0);text-decoration: none;">As noted in the introduction, this project takes a different approach from that of Shark or Spark SQL in the sense that we are not going to implement SQL semantics using Spark's primitives. On the contrary, we will implement it using MapReduce primitives. The only new thing here is that these MapReduce primitives will be executed in Spark. In fact, only a few of Spark's primitives will be used in this design.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">The approach of executing Hive’s MapReduce primitives on Spark that is different from what Shark or Spark SQL does has the following direct advantages:</span></p><ol><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark users will automatically get the whole set of Hive’s rich features, including any new features that Hive might introduce in the future.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">This approach avoids or reduces the necessity of any customization work in Hive’s Spark execution engine.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">It will also limit the scope of the project and reduce long-term maintenance by keeping Hive-on-Spark congruent to Hive MapReduce and Tez.</span></p></li></ol><p><span style="color: rgb(0,0,0);text-decoration: none;">The main work to implement the Spark execution engine for Hive lies in two folds: query planning, where Hive operator plan from semantic analyzer is further translated a task plan that Spark can execute, and query execution, where the generated Spark plan gets actually executed in the Spark cluster. Of course, there are other functional pieces, miscellaneous yet indispensable such as monitoring, counters, statistics, etc. Some important design details are thus also outlined below.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">It’s worth noting that though Spark is written largely in Scala, it provides client APIs in several languages including Java. Naturally we choose Spark Java APIs for the integration, and no Scala knowledge is needed for this project.</span></p><h2 id="HiveonSpark-3.1QueryPlanning"><span style="color: rgb(0,0,0);text-decoration: none;">3.1 Query Planning</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">Currently for a given user query Hive semantic analyzer generates an operator plan that's composed of a graph of logical operators such as </span><span style="color: rgb(0,0,0);text-decoration: none;">TableScanOperator</span><span style="color: rgb(0,0,0);text-decoration: none;">, </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceSink</span><span style="color: rgb(0,0,0);text-decoration: none;">, </span><span style="color: rgb(0,0,0);text-decoration: none;">FileSink</span><span style="color: rgb(0,0,0);text-decoration: none;">, </span><span style="color: rgb(0,0,0);text-decoration: none;">GroupByOperator</span><span style="color: rgb(0,0,0);text-decoration: none;">, etc. </span><span style="color: rgb(0,0,0);text-decoration: none;">MapReduceCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;"> compiles a graph of </span><span style="color: rgb(0,0,0);text-decoration: none;">MapReduceTask</span><span style="color: rgb(0,0,0);text-decoration: none;">s and other helper tasks (such as </span><span style="color: rgb(0,0,0);text-decoration: none;">MoveTask</span><span style="color: rgb(0,0,0);text-decoration: none;">) from the logical, operator plan. Tez behaves similarly, yet generates a </span><span style="color: rgb(0,0,0);text-decoration: none;">TezTask</span><span style="color: rgb(0,0,0);text-decoration: none;"> that combines otherwise multiple MapReduce tasks into a single Tez task.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">For Spark, we will introduce </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;">, parallel to </span><span style="color: rgb(0,0,0);text-decoration: none;">MapReduceCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">TezCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;">. Its main responsibility is to compile from Hive logical operator plan a plan that can be execute on Spark. Thus, we will have </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask</span><span style="color: rgb(0,0,0);text-decoration: none;">, depicting a job that will be executed in a Spark cluster, and </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;">, describing the plan of a Spark task. Thus, </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;"> translates a Hive's operator plan into a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> instance.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">During the task plan generation, </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkCompiler</span><span style="color: rgb(0,0,0);text-decoration: none;"> may perform physical optimizations that's suitable for Spark. However, for first phase of the implementation, we will focus less on this unless it's easy and obvious. Further optimization can be done down the road in an incremental manner as we gain more and more knowledge and experience with Spark.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">How to generate </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> from Hive’s operator plan is left to the implementation. However, there seems to be a lot of common logics between Tez and Spark as well as between MapReduce and Spark. If feasible, we will extract the common logic and package it into a shareable form, leaving the specific </span><span style="color: rgb(0,0,0);text-decoration: none;">    </span><span style="color: rgb(0,0,0);text-decoration: none;">implementations to each task compiler, without destabilizing either MapReduce or Tez.</span><span style="color: rgb(0,0,0);text-decoration: none;">    </span></p><h2 id="HiveonSpark-3.2JobExecution"><span style="color: rgb(0,0,0);text-decoration: none;">3.2 Job Execution</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">A </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask</span><span style="color: rgb(0,0,0);text-decoration: none;"> instance can be executed by Hive's task execution framework in the same way as for other tasks. Internally, the </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask.execute()</span><span style="color: rgb(0,0,0);text-decoration: none;"> method will make RDDs and functions out of a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> instance, and submit the execution to the Spark cluster via a Spark client.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Once the Spark work is submitted to the Spark cluster, Spark client will continue to monitor the job execution and report progress. A Spark job can be monitored via </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkListener</span><span style="color: rgb(0,0,0);text-decoration: none;"> APIs. Currently not available in Spark Java API, We expect they will be made available soon with the help from Spark community.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">With </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkListener</span><span style="color: rgb(0,0,0);text-decoration: none;"> APIs, we will add a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkJobMonitor</span><span style="color: rgb(0,0,0);text-decoration: none;"> class that handles printing of status as well as reporting the final result. This class provides similar functions as </span><span style="color: rgb(0,0,0);text-decoration: none;">HadoopJobExecHelper</span><span style="color: rgb(0,0,0);text-decoration: none;"> used for MapReduce processing, or </span><span style="color: rgb(0,0,0);text-decoration: none;">TezJobMonitor</span><span style="color: rgb(0,0,0);text-decoration: none;"> used for Tez job processing, and will also retrieve and print the top level exception thrown at execution time, in case of job failure.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark job submission is done via a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext</span><span style="color: rgb(0,0,0);text-decoration: none;"> object that’s instantiated with user’s configuration. When a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask</span><span style="color: rgb(0,0,0);text-decoration: none;"> is executed by Hive, such context object is created in the current user session. With the context object, RDDs corresponding to Hive tables are created and </span><span style="color: rgb(0,0,0);text-decoration: none;">MapFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> (more details below) that are built from Hive’s </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> and applied to the RDDs. Job execution is triggered by applying a </span><span style="color: rgb(0,0,0);text-decoration: none;">foreach(</span><span style="color: rgb(0,0,0);text-decoration: none;">) transformation on the RDDs with a dummy function.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">One </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext</span><span style="color: rgb(0,0,0);text-decoration: none;"> per user session is right thing to do, but it seems that Spark assumes one </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext</span><span style="color: rgb(0,0,0);text-decoration: none;"> per application because of some thread-safety issues. We expect that Spark community will be able to address this issue timely.</span></p><h2 id="HiveonSpark-3.3DesignConsiderations"><span style="color: rgb(0,0,0);text-decoration: none;">3.3 Design Considerations</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">This section covers the main design considerations for a number of important components, either new that will be introduced or existing that deserves special treatment. For other existing components that aren’t named out, such as UDFs and custom Serdes, we expect that special considerations are either not needed or insignificant.</span></p><h3 id="HiveonSpark-TableasRDD"><span style="color: rgb(0,0,0);text-decoration: none;">Table as RDD</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">A Hive table is nothing but a bunch of files and folders on HDFS. Spark primitives are applied to RDDs. Thus, naturally Hive tables will be treated as RDDs in the Spark execution engine. However, Hive table is more complex than a HDFS file. It can have partitions and buckets, dealing with heterogeneous input formats and schema evolution. As a result, the treatment may not be that simple, potentially having complications, which we need to be aware of.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">It's possible we need to extend Spark's Hadoop RDD and implement a Hive-specific RDD. While RDD extension seems easy in Scala, this can be challenging as Spark's Java APIs lack such capability. We will find out if RDD extension is needed and if so we will need help from Spark community on the Java APIs.</span></p><h3 id="HiveonSpark-SparkWork"><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">As discussed above, </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask</span><span style="color: rgb(0,0,0);text-decoration: none;"> will use </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;">, which describes the task plan that the Spark job is going to execute upon. </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> will be very similar to </span><span style="color: rgb(0,0,0);text-decoration: none;">TezWork</span><span style="color: rgb(0,0,0);text-decoration: none;">, which is basically composed of </span><span style="color: rgb(0,0,0);text-decoration: none;">MapWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> at the leaves and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> (occassionally, </span><span style="color: rgb(0,0,0);text-decoration: none;">UnionWork</span><span style="color: rgb(0,0,0);text-decoration: none;">) in all other nodes.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Defining </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> in terms of </span><span style="color: rgb(0,0,0);text-decoration: none;">MapWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> makes the new concept easier to be understood. The “</span><span style="color: rgb(0,0,0);text-decoration: none;">explain</span><span style="color: rgb(0,0,0);text-decoration: none;">” command will show a pattern that Hive users are familiar with.</span></p><h3 id="HiveonSpark-SparkTask"><span style="color: rgb(0,0,0);text-decoration: none;">SparkTask</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">To execute the work described by a </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> instance, some further translation is necessary, as </span><span style="color: rgb(0,0,0);text-decoration: none;">MapWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> are MapReduce-oriented concepts, and implementing them with Spark requires some traverse of the plan and generation of Spark constructs (RDDs, functions). How to traverse and translate the plan is left to the implementation, but this is very Spark specific, thus having no exposure to or impact on other components.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Above mentioned </span><span style="color: rgb(0,0,0);text-decoration: none;">MapFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> will be made from </span><span style="color: rgb(0,0,0);text-decoration: none;">MapWork</span><span style="color: rgb(0,0,0);text-decoration: none;">, specifically, the operator chain starting from </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecMapper.map()</span><span style="color: rgb(0,0,0);text-decoration: none;"> method. </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecMapper</span><span style="color: rgb(0,0,0);text-decoration: none;"> class implements MapReduce Mapper interface, but the implementation in Hive contains some code that can be reused for Spark. Therefore, we will likely extract the common code into a separate class, </span><span style="color: rgb(0,0,0);text-decoration: none;">MapperDriver</span><span style="color: rgb(0,0,0);text-decoration: none;">, to be shared by both MapReduce and Spark. Note that this is just a matter of refactoring rather than redesigning.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">(Tez probably had the same situation. However, Tez has chosen to create a separate class, </span><span style="color: rgb(0,0,0);text-decoration: none;">RecordProcessor</span><span style="color: rgb(0,0,0);text-decoration: none;">, to do something similar.)</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Similarly, </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> will be made of </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> instance from </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;">. To Spark, </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> has no difference from </span><span style="color: rgb(0,0,0);text-decoration: none;">MapFunction</span><span style="color: rgb(0,0,0);text-decoration: none;">, but the function's implementation will be different, made of the operator chain starting from </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecReducer.reduce()</span><span style="color: rgb(0,0,0);text-decoration: none;">. Also because some code in </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecReducer</span><span style="color: rgb(0,0,0);text-decoration: none;"> are to be reused, likely we will extract the common code into a separate class, </span><span style="color: rgb(0,0,0);text-decoration: none;">ReducerDriver</span><span style="color: rgb(0,0,0);text-decoration: none;">, so as to be shared by both MapReduce and Spark.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">All functions, including </span><span style="color: rgb(0,0,0);text-decoration: none;">MapFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> needs to be serializable as Spark needs to ship them to the cluster. This could be tricky as how to package the functions impacts the serialization of the functions, and Spark is implicit on this.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Note that Spark's built-in map and reduce transformation operators are functional with respect to each record. For example,  Hive's operators, however, need to be initialized before being called to process rows and be closed when done processing. </span><span style="color: rgb(0,0,0);text-decoration: none;">MapFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> and </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceFunction</span><span style="color: rgb(0,0,0);text-decoration: none;"> will have to perform all those in a single </span><span style="color: rgb(0,0,0);text-decoration: none;">call() </span><span style="color: rgb(0,0,0);text-decoration: none;">method. For the purpose of using Spark as an alternate execution backend for Hive, we will be using the </span><span style="color: rgb(0,0,0);text-decoration: none;">mapPartitions</span><span style="color: rgb(0,0,0);text-decoration: none;"> transformation operator on RDDs, which provides an iterator on a whole partition of data. With the iterator in control, Hive can initialize the operator chain before processing the first row, and de-initialize it after all input is consumed.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">It's worth noting that during the prototyping Spark caches function globally in certain cases, thus keeping stale state of the function. Such culprit is hard to detect and hopefully Spark will be more specific in documenting features down the road.</span></p><h3 id="HiveonSpark-Shuffle,Group,andSort"><span style="color: rgb(0,0,0);text-decoration: none;">Shuffle, Group, and Sort</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">While this comes for “free” for MapReduce and Tez, we will need to provide an equivalent for Spark. Fortunately, Spark provides a few transformations that are suitable to substitute MapReduce’s shuffle capability, such as </span><span style="color: rgb(0,0,0);text-decoration: none;">partitionBy</span><span style="color: rgb(0,0,0);text-decoration: none;">, </span><span style="color: rgb(0,0,0);text-decoration: none;">groupByKey</span><span style="color: rgb(0,0,0);text-decoration: none;">, and </span><span style="color: rgb(0,0,0);text-decoration: none;">sortByKey</span><span style="color: rgb(0,0,0);text-decoration: none;">. Transformation </span><span style="color: rgb(0,0,0);text-decoration: none;">partitionBy </span><span style="color: rgb(0,0,0);text-decoration: none;">does pure shuffling (no grouping or sorting), </span><span style="color: rgb(0,0,0);text-decoration: none;">groupByKey</span><span style="color: rgb(0,0,0);text-decoration: none;"> does shuffling and grouping, and </span><span style="color: rgb(0,0,0);text-decoration: none;">sortByKey()</span><span style="color: rgb(0,0,0);text-decoration: none;"> does shuffling plus sorting. Therefore, for each </span><span style="color: rgb(0,0,0);text-decoration: none;">ReduceSinkOperator</span><span style="color: rgb(0,0,0);text-decoration: none;"> in </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkWork</span><span style="color: rgb(0,0,0);text-decoration: none;">, we will need to inject one of the transformations. </span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Having the capability of selectively choosing the exact shuffling behavior provides opportunities for optimization. For instance, Hive's </span><span style="color: rgb(0,0,0);text-decoration: none;">groupBy</span><span style="color: rgb(0,0,0);text-decoration: none;"> doesn't require the key to be sorted, but MapReduce does it nevertheless. In Spark, we can choose </span><span style="color: rgb(0,0,0);text-decoration: none;">sortByKey</span><span style="color: rgb(0,0,0);text-decoration: none;"> only if necessary key order is important (such as for SQL </span><span style="color: rgb(0,0,0);text-decoration: none;">order by</span><span style="color: rgb(0,0,0);text-decoration: none;">).</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">While </span><span style="color: rgb(0,0,0);text-decoration: none;">sortByKey </span><span style="color: rgb(0,0,0);text-decoration: none;">provides no grouping, it’s easy to group the keys as rows with the same key will come consecutively. On the other hand,  </span><span style="color: rgb(0,0,0);text-decoration: none;">groupByKey</span><span style="color: rgb(0,0,0);text-decoration: none;"> clusters the keys in a collection, which naturally fits the MapReduce’s reducer interface.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">As Hive is more sophisticated in using MapReduce keys to implement operations that’s not directly available such as </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;">, above mentioned transformations may not behave exactly as Hive needs. Thus, we need to be diligent in identifying potential issues as we move forward.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Finally, it seems that Spark community is in the process of improving/changing the shuffle related APIs. Thus, this part of design is subject to change. Please refer to </span><a href="https://issues.apache.org/jira/browse/SPARK-2044" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(17,85,204);text-decoration: underline;">https://issues.apache.org/jira/browse/SPARK-2044</span></a><span style="color: rgb(0,0,0);text-decoration: none;"> for the details on Spark shuffle-related improvement. </span></p><h3 id="HiveonSpark-Join"><span style="color: rgb(0,0,0);text-decoration: none;">Join</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">It’s rather complicated in implementing </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;"> in MapReduce world, as manifested in Hive. Hive has reduce-side </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;"> as well as map-side </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;"> (including map-side hash lookup and map-side sorted merge). We will keep Hive’s </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;"> implementations. However, extra attention needs to be paid on the shuffle behavior (key generation, partitioning, sorting, etc), since Hive extensively uses MapReduce’s shuffling in implementing reduce-side </span><span style="color: rgb(0,0,0);text-decoration: none;">join</span><span style="color: rgb(0,0,0);text-decoration: none;">. It’s expected that Spark is, or will be, able to provide flexible control over the shuffling, as pointed out in the previous section(</span><a href="https://docs.google.com/a/cloudera.com/document/d/11xXVgma6UPa32cW_W64BwBssnA0d6RX4jUsATOzgkcw/edit#heading=h.rnmzzu57lmuh" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(17,85,204);text-decoration: underline;">Shuffle, Group, and Sort</span></a><span style="color: rgb(0,0,0);text-decoration: none;">).</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">See: <a href="Hive+on+Spark%253A+Join+Design+Master">Hive on Spark: Join Design Master</a> for detailed design.</span></p><h3 id="HiveonSpark-NumberofTasks"><span style="color: rgb(0,0,0);text-decoration: none;">Number of Tasks</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">As specified above, Spark transformations such as </span><span style="color: rgb(0,0,0);text-decoration: none;">partitionBy</span><span style="color: rgb(0,0,0);text-decoration: none;"> will be used to connect mapper-side’s operations to reducer-side’s operations. The number of partitions can be optionally given for those transformations, which basically dictates the number of reducers.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">The determination of the number of reducers will be the same as it’s for MapReduce and Tez.</span></p><h3 id="HiveonSpark-LocalMapReduceTasks"><span style="color: rgb(0,0,0);text-decoration: none;">Local MapReduce Tasks</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">While we could see the benefits of running local jobs on Spark, such as avoiding sinking data to a file and then reading it from the file to memory, in the short term, those tasks will still be executed the same way as it is today. This means that Hive will always have to submit MapReduce jobs when executing locally. However, this can be further investigated and evaluated down the road.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">The same applies for presenting the query result to the user. Presently, a fetch operator is used on the client side to fetch rows from the temporary file (produced by </span><span style="color: rgb(0,0,0);text-decoration: none;">FileSink</span><span style="color: rgb(0,0,0);text-decoration: none;"> in the query plan). It's possible to have the </span><span style="color: rgb(0,0,0);text-decoration: none;">FileSink</span><span style="color: rgb(0,0,0);text-decoration: none;"> to generate an in-memory RDD instead and the fetch operator can directly read rows from the RDD. Again this can be investigated and implemented as a future work.</span><span style="color: rgb(0,0,0);text-decoration: none;">    </span></p><h3 id="HiveonSpark-SemanticAnalysisandLogicalOptimizations"><span style="color: rgb(0,0,0);text-decoration: none;">Semantic Analysis and Logical Optimizations</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Neither semantic analyzer nor any logical optimizations will change. Physical optimizations and MapReduce plan generation have already been moved out to separate classes as part of Hive on Tez work.</span></p><h3 id="HiveonSpark-JobDiagnostics"><span style="color: rgb(0,0,0);text-decoration: none;">Job Diagnostics</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Basic “job succeeded/failed” as well as progress will be as discussed in “Job monitoring”. Hive’s current way of trying to fetch additional information about failed jobs may not be available immediately, but this is another area that needs more research.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark provides WebUI for each </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext</span><span style="color: rgb(0,0,0);text-decoration: none;"> while it’s running. Note that this information is only available for the duration of the application by default. To view the web UI after the fact, set </span><span style="color: rgb(0,0,0);text-decoration: none;">spark.eventLog.enabled</span><span style="color: rgb(0,0,0);text-decoration: none;"> to </span><span style="color: rgb(0,0,0);text-decoration: none;">true</span><span style="color: rgb(0,0,0);text-decoration: none;"> before starting the application. This configures Spark to log Spark events that encode the information displayed in the UI to persisted storage.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark’s Standalone Mode cluster manager also has its own web UI. If an application has logged events over the course of its lifetime, then the Standalone master’s web UI will automatically re-render the application’s UI after the application has finished.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">If Spark is run on Mesos or YARN, it is still possible to reconstruct the UI of a finished application through Spark’s history server, provided that the application’s event logs exist.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">For more information about Spark monitoring, visit</span><a href="http://spark.apache.org/docs/latest/monitoring.html" style="text-decoration: none;" class="external-link" rel="nofollow"><span style="color: rgb(0,0,0);text-decoration: none;"> </span><span style="color: rgb(17,85,204);text-decoration: underline;">http://spark.apache.org/docs/latest/monitoring.html</span></a><span style="color: rgb(0,0,0);text-decoration: none;">.</span></p><h3 id="HiveonSpark-CountersandMetrics"><span style="color: rgb(0,0,0);text-decoration: none;">Counters and Metrics</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark has accumulators which are variables that are only “added” to through an associative operation and can therefore be efficiently supported in parallel. They can be used to implement counters (as in MapReduce) or sums. Spark natively supports accumulators of numeric value types and standard mutable collections, and programmers can add support for new types. In Hive, we may use Spark accumulators to implement Hadoop counters, but this may not be done right way.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark publishes runtime metrics for a running job. However, it’s very likely that the metrics are different from either MapReduce or Tez, not to mention the way to extract the metrics. The topic around this deserves a separate document, but this can be certainly improved upon incrementally.</span></p><h3 id="HiveonSpark-ExplainStatements"><span style="color: rgb(0,0,0);text-decoration: none;">Explain Statements</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Explain statements will be similar to that of </span><span style="color: rgb(0,0,0);text-decoration: none;">TezWork</span><span style="color: rgb(0,0,0);text-decoration: none;">.</span></p><h3 id="HiveonSpark-HiveVariables"><span style="color: rgb(0,0,0);text-decoration: none;">Hive Variables</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Hive variables will continue to work as it is today. The variables will be passed through to the execution engine as before. However, some execution engine related variables may not be applicable to Spark, in which case, they will be simply ignored.</span></p><h3 id="HiveonSpark-Union"><span style="color: rgb(0,0,0);text-decoration: none;">Union</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">While it's mentioned above that we will use MapReduce primitives to implement SQL semantics in the Spark execution engine, union is one exception. While it's possible to implement it with MapReduce primitives, it takes up to three MapReduce jobs to union two datasets. Using Spark's union transformation should significantly reduce the execution time and promote interactivity.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">In fact, Tez has already deviated from MapReduce practice with respect to union. There is an existing </span><span style="color: rgb(0,0,0);text-decoration: none;">UnionWork</span><span style="color: rgb(0,0,0);text-decoration: none;"> where a union operator is translated to a work unit.</span></p><h3 id="HiveonSpark-ConcurrencyandThreadSafety"><span style="color: rgb(0,0,0);text-decoration: none;">Concurrency and Thread Safety</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark launches mappers and reducers differently from MapReduce in that a worker may process multiple HDFS splits in a single JVM. However, Hive’s map-side operator tree or reduce-side operator tree operates in a single thread in an exclusive JVM. Reusing the operator trees and putting them in a shared JVM with each other will more than likely cause concurrency and thread safety issues. Such problems, such as static variables, have surfaced in the initial prototyping. For instance, variable </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecMapper.done</span><span style="color: rgb(0,0,0);text-decoration: none;"> is used to determine if a mapper has finished its work. If two </span><span style="color: rgb(0,0,0);text-decoration: none;">ExecMapper</span><span style="color: rgb(0,0,0);text-decoration: none;"> instances exist in a single JVM, then one mapper that finishes earlier will prematurely terminate the other also. We expect there will be a fair amount of work to make these operator tree thread-safe and contention-free. However, this work should not have any impact on other execution engines.</span></p><h3 id="HiveonSpark-BuildInfrastructure"><span style="color: rgb(0,0,0);text-decoration: none;">Build Infrastructure</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">There will be a new “ql” dependency on Spark. Currently Spark client library comes in a single jar. The spark jar will be handled the same way Hadoop jars are handled: they will be used during compile, but not included in the final distribution. Rather we will depend on them being installed separately. The spark jar will only have to be present to run Spark jobs, they are not needed for either MapReduce or Tez execution.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">On the other hand, to run Hive code on Spark, certain Hive libraries and their dependencies need to be distributed to Spark cluster by calling </span><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext.addJar()</span><span style="color: rgb(0,0,0);text-decoration: none;"> method. As Spark also depends on Hadoop and other libraries, which might be present in Hive’s dependents yet with different versions, there might be some challenges in identifying and resolving library conflicts. Jetty libraries posted such a challenge during the prototyping.</span></p><h3 id="HiveonSpark-MiniSparkCluster"><span style="color: rgb(0,0,0);text-decoration: none;">Mini Spark Cluster</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Spark jobs can be run local by giving “</span><span style="color: rgb(0,0,0);text-decoration: none;">local</span><span style="color: rgb(0,0,0);text-decoration: none;">” as the master URL. Most testing will be performed in this mode. In the same time, Spark offers a way to run jobs in a local cluster, a cluster made of a given number of processes in the local machine. We will further determine if this is a good way to run Hive’s Spark-related tests.</span></p><h3 id="HiveonSpark-Testing"><span style="color: rgb(0,0,0);text-decoration: none;">Testing</span></h3><p><span style="color: rgb(0,0,0);text-decoration: none;">Testing, including pre-commit testing, is the same as for Tez. Currently Hive has a coverage problem as there are a few variables that requires full regression suite run, such as Tez vs MapReduce, vectorization on vs off, etc. We propose rotating those variables in pre-commit test run so that enough coverage is in place while testing time isn’t prolonged.</span></p><h2 id="HiveonSpark-3.4PotentiallyRequiredWorkfromSpark"><span style="color: rgb(0,0,0);text-decoration: none;">3.4 Potentially Required Work from Spark</span></h2><p><span style="color: rgb(0,0,0);text-decoration: none;">During the course of prototyping and design, a few issues on Spark have been identified, as shown throughout the document. Potentially more, but the following is a summary of improvement that’s needed from Spark community for the project:</span></p><ol><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Job monitoring API in Java.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">SparkContext</span><span style="color: rgb(0,0,0);text-decoration: none;"> thread safety issue.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Improve shuffle functionality and API.</span></p></li><li style="text-decoration: none;"><p><span style="color: rgb(0,0,0);text-decoration: none;">Potentially, Java API for extending RDD.</span></p></li></ol><h1 id="HiveonSpark-4.Summary"><span style="color: rgb(0,0,0);text-decoration: none;">4. Summary</span></h1><p><span style="color: rgb(0,0,0);text-decoration: none;">It can be seen from above analysis that the project of Spark on Hive is simple and clean in terms of functionality and design, while complicated and involved in implementation, which may take significant time and resources. Therefore, we are going to take a phased approach and expect that the work on optimization and improvement will be on-going in a relatively long period of time while all basic functionality will be there in the first phase.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Secondly, we expect the integration between Hive and Spark will not be always smooth. Functional gaps may be identified and problems may arise. We anticipate that Hive community and Spark community will work closely to resolve any obstacles that might come on the way.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;">Nevertheless, we believe that the impact on existing code path is minimal. While Spark execution engine may take some time to stabilize, MapReduce and Tez should continue working as it is.</span></p><p><span style="color: rgb(0,0,0);text-decoration: none;"><br /></span></p>

                
        
    
        </div>

        <!--
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
         <rdf:Description
    rdf:about="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark"
    dc:identifier="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark"
    dc:title="Hive on Spark"
    trackback:ping="https://cwiki.apache.org/confluence/rpc/trackback/42567714"/>
</rdf:RDF>
-->

                        
    



<div id="labels-section" class="pageSection group">
    <div class="labels-section-content content-column" entityid="42567714" entitytype="page">
	<div class="labels-content">
		
    <ul class="label-list label-list-right ">
            <li class="no-labels-message">
            No labels
        </li>
            </ul>

    </div>
</div>
</div>
        
		
            




            
    








                        
    
<div id="comments-section" class="pageSection group">
        
    



</div>


                
    
            
</div>


    




    
    

    
    
    


    
<div id="space-tools-web-items" class="hidden">
                <div data-label="Overview" data-href="/confluence/spaces/viewspacesummary.action?key=Hive">Overview</div>
            <div data-label="Content Tools" data-href="/confluence/pages/reorderpages.action?key=Hive">Content Tools</div>
            <div data-label="Add-ons" data-href="/confluence/spaces/snippeterrors.action?key=Hive">Add-ons</div>
    </div>




    </div><!-- \#main -->
        
    
        
            
            

<div id="footer" role="contentinfo">
    <section class="footer-body">

                                                            <p class="license license-opensource">
                    Powered by a free <b>Atlassian Confluence Open Source Project License</b> granted to Apache Software Foundation. <a href="http://www.atlassian.com/c/conf/11461">Evaluate Confluence today</a>.<br>
                </p>
                    
        

        <ul id="poweredby">
            <li class="noprint">Powered by <a href="http://www.atlassian.com/software/confluence" class="hover-footer-link">Atlassian Confluence</a> <span id='footer-build-information'>5.8.4</span>, <a href="http://www.atlassian.com/software/confluence/overview/team-collaboration-software?utm_source=confluence-footer" class="hover-footer-link">Team Collaboration Software</a></li>
            <li class="print-only">Printed by Atlassian Confluence 5.8.4, Team Collaboration Software.</li>
            <li class="noprint"><a href="https://jira.atlassian.com/browse/CONF" class="hover-footer-link">Report a bug</a></li>
            <li class="noprint"><a href="http://www.atlassian.com/about/connected.jsp?s_kwcid=Confluence-stayintouch" class="hover-footer-link">Atlassian News</a></li>
        </ul>

        

        <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>

                    
        
    </section>
</div>

    
</div>

</div><!-- \#full-height-container -->
</div><!-- \#page -->
</body>
</html>
